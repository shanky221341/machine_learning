{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_columns=1000\n",
    "pd.options.display.max_rows=1000\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "sys.path.insert(0, \"C:\\\\Users\\\\vberlia\\\\Documents\\\\machine_learning\")\n",
    "import itertools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machineLearning.dataSummary import DataSummary\n",
    "from machineLearning.visualizations import Visualization\n",
    "from machineLearning.ploty_visualization import PlotlyVisualization\n",
    "import plotly.plotly as py\n",
    "from machineLearning.missingValues import MissingValue\n",
    "from machineLearning.models import Model\n",
    "from machineLearning.modelInputs import KNNInputs\n",
    "from machineLearning.pipelines import Pipelines\n",
    "from machineLearning.featureCreation import CreateMeanLookupFeature\n",
    "from machineLearning.featureCreation import CreateMedianLookupFeature\n",
    "from machineLearning.featureCreation import CreateFrequencyLookupFeature\n",
    "from machineLearning.featureCreation import CreateOneHotEncoding\n",
    "from machineLearning.credit_prediction import classification_report\n",
    "from machineLearning.featureCreation import CustomCutter\n",
    "from machineLearning.credit_prediction import raw_features\n",
    "from machineLearning.credit_prediction import create_features\n",
    "from machineLearning.credit_prediction import prep_data\n",
    "from machineLearning.featureCreation import IsMissingFeature\n",
    "from sklearn import linear_model\n",
    "from machineLearning.missingValues import CustomQuantitativeImputer\n",
    "from machineLearning.misc import Misc\n",
    "from machineLearning.missingValues import CustomEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import ggplot\n",
    "from ggplot import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "application_train=pd.read_csv(\"C:/Users/vberlia/Documents/data/credit_prediction/all/application_train.csv\")\n",
    "# application_newData=pd.read_csv(\"C:/Users/vberlia/Documents/data/credit_prediction/all/application_test.csv\")\n",
    "# bureau=pd.read_csv(\"C:/Users/vberlia/Documents/data/credit_prediction/all/bureau.csv\")\n",
    "# bureau_balance=pd.read_csv(\"C:/Users/vberlia/Documents/data/credit_prediction/all/bureau_balance.csv\")\n",
    "# # credit_card_balance=pd.read_csv(\"C:/Users/vberlia/Documents/data/credit_prediction/all/credit_card_balance.csv\")\n",
    "home_credit_col_desc=pd.read_csv(\"C:/Users/vberlia/Documents/data/credit_prediction/all/HomeCredit_columns_description.csv\",encoding = \"ISO-8859-1\")\n",
    "# intall_payment=pd.read_csv(\"C:/Users/vberlia/Documents/data/credit_prediction/all/installments_payments.csv\")\n",
    "# pos_cash=pd.read_csv(\"C:/Users/vberlia/Documents/data/credit_prediction/all/POS_CASH_balance.csv\")\n",
    "# prev_app=pd.read_csv(\"C:/Users/vberlia/Documents/data/credit_prediction/all/previous_application.csv\")\n",
    "# sample_submi=pd.read_csv(\"C:/Users/vberlia/Documents/data/credit_prediction/all/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sample=application_train.sample(10000,random_state=0)\n",
    "train_sample=train_sample.reset_index()\n",
    "original_index=train_sample['index']\n",
    "train_sample=train_sample.drop('index',axis=1)\n",
    "\n",
    "X=train_sample.values\n",
    "Y=train_sample['TARGET']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.10, random_state=42)\n",
    "X_train=pd.DataFrame(X_train)\n",
    "X_train.columns=train_sample.columns\n",
    "X_test=pd.DataFrame(X_test)\n",
    "X_test.columns=train_sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_columns = raw_features.features.raw_columns\n",
    "\n",
    "\"\"\"\n",
    "Enter the create features function\n",
    "and data preparer function\n",
    "\"\"\"\n",
    "final_pipeline=create_features.CreateFeatures.create_all_features1()\n",
    "dataPreparer=prep_data.PrepData.dataPreparer1\n",
    "\n",
    "\"\"\"\n",
    "Fitting Logistic Regression: \n",
    "Setup the hyperparameters\n",
    "\"\"\"\n",
    "\n",
    "algorithm='LR'\n",
    "\n",
    "class_weight=['balanced','None']\n",
    "C=[0.001, 0.01, 0.1, 0.3,0.5,0.7,0.9,1,2,5,9,13,15,17,19,21,50,100,1000]\n",
    "penalty=['l2']\n",
    "\n",
    "# class_weight=['balanced']\n",
    "# C=[21]\n",
    "# penalty=['l2']\n",
    "\n",
    "hyperparams=[class_weight,C,penalty]\n",
    "combs=list(itertools.product(*hyperparams))\n",
    "\n",
    "# Save the result in the file\n",
    "result_file=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model Function\n",
    "def build_model(X_train,standardize_input=1,save_result=False,running_in_cdsw=False):\n",
    "    for col in raw_columns:\n",
    "        X_train[col]=X_train[col].astype('float64')\n",
    "\n",
    "    for col in raw_columns:\n",
    "        X_test[col]=X_test[col].astype('float64')\n",
    "\n",
    "    # Data Preparer function -> should prepare data for all train, test and new data. Because\n",
    "    # every data kind(train, test and new data) goes through the same preparation \n",
    "    # phase\n",
    "    has_fitted_the_main_pipelines=0\n",
    "\n",
    "    X_train['TARGET']=X_train['TARGET'].astype('int')\n",
    "    X_test['TARGET']=X_test['TARGET'].astype('int')\n",
    "    '''\n",
    "    This should be underlying order\n",
    "    '''\n",
    "    X_train_prepared,has_fitted_the_main_pipelines=dataPreparer(X_train,has_fitted_the_main_pipelines,final_pipeline,'train')\n",
    "    X_test_prepared,has_fitted_the_main_pipelines=dataPreparer(X_test,has_fitted_the_main_pipelines,final_pipeline,'test')\n",
    "    if running_in_cdsw:\n",
    "        new_data_prepared,has_fitted_the_main_pipelines=dataPreparer(application_newData,has_fitted_the_main_pipelines,final_pipeline,'new_data')\n",
    "\n",
    "    col_list=X_train_prepared.columns\n",
    "    # Apply scaling\n",
    "    if standardize_input==1:\n",
    "        standardiser= StandardScaler()\n",
    "        X_train_target=X_train_prepared['TARGET']\n",
    "        X_test_target=X_test_prepared['TARGET']\n",
    "\n",
    "        standardiser.fit(X_train_prepared.iloc[:, :-1])\n",
    "        X_train_prepared=pd.DataFrame(standardiser.transform(X_train_prepared.iloc[:, :-1]))\n",
    "        X_train_prepared['TARGET']=X_train_target\n",
    "        X_test_prepared=pd.DataFrame(standardiser.transform(X_test_prepared.iloc[:, :-1]))\n",
    "        X_test_prepared['TARGET']=X_test_target\n",
    "        if running_in_cdsw:\n",
    "            new_data_prepared=pd.DataFrame(standardiser.transform(new_data_prepared))\n",
    "            new_data_prepared.columns=col_list[:-1]\n",
    "\n",
    "    X_train_prepared.columns=col_list\n",
    "    X_test_prepared.columns=col_list\n",
    "#     X_train_prepared.to_csv(\"C:/Users/vberlia/Documents/data/prep1.csv\",index=None)\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    Fitting Logistic Regression: \n",
    "    \"\"\"\n",
    "    all_report=pd.DataFrame()\n",
    "    for param in combs:\n",
    "\n",
    "        model = linear_model.LogisticRegression(solver='sag',n_jobs=2)\n",
    "        params = {\"penalty\":param[2], \"C\":param[1],\"class_weight\":param[0]}\n",
    "\n",
    "        model.set_params(**params)\n",
    "        model.fit(X_train_prepared.iloc[:, :-1], X_train_prepared.iloc[:, -1])\n",
    "        accuracy_lr = model.score(X_test_prepared.iloc[:, :-1], X_test_prepared.iloc[:, -1])        \n",
    "\n",
    "        prediction_result = pd.DataFrame()\n",
    "        predictions = pd.DataFrame(model.predict_proba(X_test_prepared.iloc[:, :-1]))\n",
    "        predictions.columns = ['class_' + str(item) for item in list(model.classes_)]\n",
    "        predictions['true_label'] = X_test_prepared.iloc[:, -1]\n",
    "        predictions['predicted_label'] = model.predict(X_test_prepared.iloc[:, :-1])\n",
    "        predictions['model'] = 'LR'\n",
    "        predictions['pipeline'] = 'no-pipeline'\n",
    "        predictions['param'] = str(params)\n",
    "        prediction_result = pd.concat([prediction_result, predictions])        \n",
    "        report=classification_report.ClassificationReport.showClassificationReport(prediction_result)\n",
    "        report.insert(0, 'algorithm', algorithm)\n",
    "        report.insert(0, 'params', str(params))\n",
    "        report.insert(0, 'model', model)\n",
    "        all_report=pd.concat([all_report,report])\n",
    "    if save_result:    \n",
    "        all_report.to_csv(result_file)\n",
    "    if running_in_cdsw:    \n",
    "        return  new_data_prepared,all_report\n",
    "    else:\n",
    "        return all_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 0.001, 'class_weight': 'balanced'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[649 261]\n",
      " [ 29  61]]\n",
      "\n",
      "Auc Score: 0.7556532356532357\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.71      0.82       910\n",
      "          1       0.19      0.68      0.30        90\n",
      "\n",
      "avg / total       0.89      0.71      0.77      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 0.01, 'class_weight': 'balanced'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[632 278]\n",
      " [ 29  61]]\n",
      "\n",
      "Auc Score: 0.7528449328449328\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.69      0.80       910\n",
      "          1       0.18      0.68      0.28        90\n",
      "\n",
      "avg / total       0.89      0.69      0.76      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 0.1, 'class_weight': 'balanced'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[637 273]\n",
      " [ 31  59]]\n",
      "\n",
      "Auc Score: 0.7486568986568988\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.70      0.81       910\n",
      "          1       0.18      0.66      0.28        90\n",
      "\n",
      "avg / total       0.88      0.70      0.76      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 0.3, 'class_weight': 'balanced'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[637 273]\n",
      " [ 32  58]]\n",
      "\n",
      "Auc Score: 0.747008547008547\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.70      0.81       910\n",
      "          1       0.18      0.64      0.28        90\n",
      "\n",
      "avg / total       0.88      0.69      0.76      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 0.5, 'class_weight': 'balanced'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[637 273]\n",
      " [ 32  58]]\n",
      "\n",
      "Auc Score: 0.7467765567765567\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.70      0.81       910\n",
      "          1       0.18      0.64      0.28        90\n",
      "\n",
      "avg / total       0.88      0.69      0.76      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 0.7, 'class_weight': 'balanced'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[638 272]\n",
      " [ 32  58]]\n",
      "\n",
      "Auc Score: 0.7467399267399267\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.70      0.81       910\n",
      "          1       0.18      0.64      0.28        90\n",
      "\n",
      "avg / total       0.88      0.70      0.76      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 0.9, 'class_weight': 'balanced'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[637 273]\n",
      " [ 32  58]]\n",
      "\n",
      "Auc Score: 0.7467643467643468\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.70      0.81       910\n",
      "          1       0.18      0.64      0.28        90\n",
      "\n",
      "avg / total       0.88      0.69      0.76      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 1, 'class_weight': 'balanced'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[638 272]\n",
      " [ 32  58]]\n",
      "\n",
      "Auc Score: 0.7467277167277167\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.70      0.81       910\n",
      "          1       0.18      0.64      0.28        90\n",
      "\n",
      "avg / total       0.88      0.70      0.76      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 2, 'class_weight': 'balanced'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[636 274]\n",
      " [ 32  58]]\n",
      "\n",
      "Auc Score: 0.7466056166056166\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.70      0.81       910\n",
      "          1       0.17      0.64      0.27        90\n",
      "\n",
      "avg / total       0.88      0.69      0.76      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 5, 'class_weight': 'balanced'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[635 275]\n",
      " [ 32  58]]\n",
      "\n",
      "Auc Score: 0.7466422466422467\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.70      0.81       910\n",
      "          1       0.17      0.64      0.27        90\n",
      "\n",
      "avg / total       0.88      0.69      0.76      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 9, 'class_weight': 'balanced'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[635 275]\n",
      " [ 32  58]]\n",
      "\n",
      "Auc Score: 0.7465445665445665\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.70      0.81       910\n",
      "          1       0.17      0.64      0.27        90\n",
      "\n",
      "avg / total       0.88      0.69      0.76      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 13, 'class_weight': 'balanced'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[635 275]\n",
      " [ 32  58]]\n",
      "\n",
      "Auc Score: 0.7465445665445666\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.70      0.81       910\n",
      "          1       0.17      0.64      0.27        90\n",
      "\n",
      "avg / total       0.88      0.69      0.76      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 15, 'class_weight': 'balanced'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[635 275]\n",
      " [ 32  58]]\n",
      "\n",
      "Auc Score: 0.7464102564102565\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.70      0.81       910\n",
      "          1       0.17      0.64      0.27        90\n",
      "\n",
      "avg / total       0.88      0.69      0.76      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 17, 'class_weight': 'balanced'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[635 275]\n",
      " [ 32  58]]\n",
      "\n",
      "Auc Score: 0.7465934065934066\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.70      0.81       910\n",
      "          1       0.17      0.64      0.27        90\n",
      "\n",
      "avg / total       0.88      0.69      0.76      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 19, 'class_weight': 'balanced'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[635 275]\n",
      " [ 32  58]]\n",
      "\n",
      "Auc Score: 0.7465079365079366\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.70      0.81       910\n",
      "          1       0.17      0.64      0.27        90\n",
      "\n",
      "avg / total       0.88      0.69      0.76      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 21, 'class_weight': 'balanced'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[635 275]\n",
      " [ 32  58]]\n",
      "\n",
      "Auc Score: 0.7464835164835165\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.70      0.81       910\n",
      "          1       0.17      0.64      0.27        90\n",
      "\n",
      "avg / total       0.88      0.69      0.76      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 50, 'class_weight': 'balanced'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[636 274]\n",
      " [ 32  58]]\n",
      "\n",
      "Auc Score: 0.7463858363858364\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.70      0.81       910\n",
      "          1       0.17      0.64      0.27        90\n",
      "\n",
      "avg / total       0.88      0.69      0.76      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 100, 'class_weight': 'balanced'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[635 275]\n",
      " [ 32  58]]\n",
      "\n",
      "Auc Score: 0.7465689865689867\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.70      0.81       910\n",
      "          1       0.17      0.64      0.27        90\n",
      "\n",
      "avg / total       0.88      0.69      0.76      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 1000, 'class_weight': 'balanced'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[635 275]\n",
      " [ 32  58]]\n",
      "\n",
      "Auc Score: 0.7463736263736265\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.70      0.81       910\n",
      "          1       0.17      0.64      0.27        90\n",
      "\n",
      "avg / total       0.88      0.69      0.76      1000\n",
      "\n",
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 0.001, 'class_weight': 'None'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[910   0]\n",
      " [ 90   0]]\n",
      "\n",
      "Auc Score: 0.7421245421245422\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       910\n",
      "          1       0.00      0.00      0.00        90\n",
      "\n",
      "avg / total       0.83      0.91      0.87      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 0.01, 'class_weight': 'None'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[909   1]\n",
      " [ 90   0]]\n",
      "\n",
      "Auc Score: 0.7554945054945055\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       910\n",
      "          1       0.00      0.00      0.00        90\n",
      "\n",
      "avg / total       0.83      0.91      0.87      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 0.1, 'class_weight': 'None'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[908   2]\n",
      " [ 90   0]]\n",
      "\n",
      "Auc Score: 0.7530036630036631\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       910\n",
      "          1       0.00      0.00      0.00        90\n",
      "\n",
      "avg / total       0.83      0.91      0.87      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 0.3, 'class_weight': 'None'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[908   2]\n",
      " [ 90   0]]\n",
      "\n",
      "Auc Score: 0.7523687423687424\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       910\n",
      "          1       0.00      0.00      0.00        90\n",
      "\n",
      "avg / total       0.83      0.91      0.87      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 0.5, 'class_weight': 'None'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[907   3]\n",
      " [ 90   0]]\n",
      "\n",
      "Auc Score: 0.7521001221001221\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       910\n",
      "          1       0.00      0.00      0.00        90\n",
      "\n",
      "avg / total       0.83      0.91      0.87      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 0.7, 'class_weight': 'None'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[908   2]\n",
      " [ 90   0]]\n",
      "\n",
      "Auc Score: 0.7521001221001221\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       910\n",
      "          1       0.00      0.00      0.00        90\n",
      "\n",
      "avg / total       0.83      0.91      0.87      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 0.9, 'class_weight': 'None'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[907   3]\n",
      " [ 90   0]]\n",
      "\n",
      "Auc Score: 0.7519658119658119\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       910\n",
      "          1       0.00      0.00      0.00        90\n",
      "\n",
      "avg / total       0.83      0.91      0.87      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 1, 'class_weight': 'None'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[907   3]\n",
      " [ 90   0]]\n",
      "\n",
      "Auc Score: 0.7519169719169718\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       910\n",
      "          1       0.00      0.00      0.00        90\n",
      "\n",
      "avg / total       0.83      0.91      0.87      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 2, 'class_weight': 'None'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[907   3]\n",
      " [ 90   0]]\n",
      "\n",
      "Auc Score: 0.7521489621489622\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       910\n",
      "          1       0.00      0.00      0.00        90\n",
      "\n",
      "avg / total       0.83      0.91      0.87      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 5, 'class_weight': 'None'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[907   3]\n",
      " [ 90   0]]\n",
      "\n",
      "Auc Score: 0.7519291819291818\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       910\n",
      "          1       0.00      0.00      0.00        90\n",
      "\n",
      "avg / total       0.83      0.91      0.87      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 9, 'class_weight': 'None'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[907   3]\n",
      " [ 90   0]]\n",
      "\n",
      "Auc Score: 0.7520390720390719\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       910\n",
      "          1       0.00      0.00      0.00        90\n",
      "\n",
      "avg / total       0.83      0.91      0.87      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 13, 'class_weight': 'None'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[907   3]\n",
      " [ 90   0]]\n",
      "\n",
      "Auc Score: 0.7519047619047619\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       910\n",
      "          1       0.00      0.00      0.00        90\n",
      "\n",
      "avg / total       0.83      0.91      0.87      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 15, 'class_weight': 'None'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[908   2]\n",
      " [ 90   0]]\n",
      "\n",
      "Auc Score: 0.7519780219780221\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       910\n",
      "          1       0.00      0.00      0.00        90\n",
      "\n",
      "avg / total       0.83      0.91      0.87      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 17, 'class_weight': 'None'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[908   2]\n",
      " [ 90   0]]\n",
      "\n",
      "Auc Score: 0.7518803418803418\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       910\n",
      "          1       0.00      0.00      0.00        90\n",
      "\n",
      "avg / total       0.83      0.91      0.87      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 19, 'class_weight': 'None'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[907   3]\n",
      " [ 90   0]]\n",
      "\n",
      "Auc Score: 0.7521001221001221\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       910\n",
      "          1       0.00      0.00      0.00        90\n",
      "\n",
      "avg / total       0.83      0.91      0.87      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 21, 'class_weight': 'None'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[908   2]\n",
      " [ 90   0]]\n",
      "\n",
      "Auc Score: 0.7520268620268621\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       910\n",
      "          1       0.00      0.00      0.00        90\n",
      "\n",
      "avg / total       0.83      0.91      0.87      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 50, 'class_weight': 'None'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[907   3]\n",
      " [ 90   0]]\n",
      "\n",
      "Auc Score: 0.751941391941392\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       910\n",
      "          1       0.00      0.00      0.00        90\n",
      "\n",
      "avg / total       0.83      0.91      0.87      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 100, 'class_weight': 'None'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[908   2]\n",
      " [ 90   0]]\n",
      "\n",
      "Auc Score: 0.7520390720390722\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       910\n",
      "          1       0.00      0.00      0.00        90\n",
      "\n",
      "avg / total       0.83      0.91      0.87      1000\n",
      "\n",
      "This function will generate the classification report for each pipelines best parameter fit classification report:\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Model -> {'LR'}\n",
      "Pipeline -> no-pipeline\n",
      "\n",
      "Param -> {\"{'penalty': 'l2', 'C': 1000, 'class_weight': 'None'}\"}\n",
      "===============================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[907   3]\n",
      " [ 90   0]]\n",
      "\n",
      "Auc Score: 0.752063492063492\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       910\n",
      "          1       0.00      0.00      0.00        90\n",
      "\n",
      "avg / total       0.83      0.91      0.87      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_report=build_model(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 16)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_report.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>AUC</th>\n",
       "      <th>class_0_precision</th>\n",
       "      <th>class_0_recall</th>\n",
       "      <th>class_0_f1_score</th>\n",
       "      <th>class_0_support</th>\n",
       "      <th>class_1_precision</th>\n",
       "      <th>class_1_recall</th>\n",
       "      <th>class_1_f1_score</th>\n",
       "      <th>class_1_support</th>\n",
       "      <th>total_precision</th>\n",
       "      <th>total_recall</th>\n",
       "      <th>total_f1_score</th>\n",
       "      <th>total_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=0.001, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.001, 'class_weight': 'balanced'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.755653</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.82</td>\n",
       "      <td>910</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.30</td>\n",
       "      <td>90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=0.01, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.01, 'class_weight': 'balanced'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.752845</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.80</td>\n",
       "      <td>910</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.28</td>\n",
       "      <td>90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=0.1, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.1, 'class_weight': 'balanced'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.748657</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.81</td>\n",
       "      <td>910</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.28</td>\n",
       "      <td>90</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=0.3, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.3, 'class_weight': 'balanced'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.747009</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.81</td>\n",
       "      <td>910</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.28</td>\n",
       "      <td>90</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=0.5, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.5, 'class_weight': 'balanced'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.746777</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.81</td>\n",
       "      <td>910</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.28</td>\n",
       "      <td>90</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=0.7, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.7, 'class_weight': 'balanced'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.746740</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.81</td>\n",
       "      <td>910</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.28</td>\n",
       "      <td>90</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=0.9, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.9, 'class_weight': 'balanced'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.746764</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.81</td>\n",
       "      <td>910</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.28</td>\n",
       "      <td>90</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=1, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 1, 'class_weight': 'balanced'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.746728</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.81</td>\n",
       "      <td>910</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.28</td>\n",
       "      <td>90</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=2, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 2, 'class_weight': 'balanced'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.746606</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.81</td>\n",
       "      <td>910</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.27</td>\n",
       "      <td>90</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=5, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 5, 'class_weight': 'balanced'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.746642</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.81</td>\n",
       "      <td>910</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.27</td>\n",
       "      <td>90</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=9, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 9, 'class_weight': 'balanced'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.746545</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.81</td>\n",
       "      <td>910</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.27</td>\n",
       "      <td>90</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=13, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 13, 'class_weight': 'balanced'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.746545</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.81</td>\n",
       "      <td>910</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.27</td>\n",
       "      <td>90</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=15, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 15, 'class_weight': 'balanced'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.746410</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.81</td>\n",
       "      <td>910</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.27</td>\n",
       "      <td>90</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=17, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 17, 'class_weight': 'balanced'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.746593</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.81</td>\n",
       "      <td>910</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.27</td>\n",
       "      <td>90</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=19, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 19, 'class_weight': 'balanced'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.746508</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.81</td>\n",
       "      <td>910</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.27</td>\n",
       "      <td>90</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=21, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 21, 'class_weight': 'balanced'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.746484</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.81</td>\n",
       "      <td>910</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.27</td>\n",
       "      <td>90</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=50, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 50, 'class_weight': 'balanced'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.746386</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.81</td>\n",
       "      <td>910</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.27</td>\n",
       "      <td>90</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=100, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 100, 'class_weight': 'balanced'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.746569</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.81</td>\n",
       "      <td>910</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.27</td>\n",
       "      <td>90</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=1000, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 1000, 'class_weight': 'balanced'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.746374</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.81</td>\n",
       "      <td>910</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.27</td>\n",
       "      <td>90</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=0.001, class_weight='None', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.001, 'class_weight': 'None'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.742125</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>910</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=0.01, class_weight='None', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.01, 'class_weight': 'None'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.755495</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>910</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=0.1, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.1, 'class_weight': 'None'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.753004</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>910</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=0.3, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.3, 'class_weight': 'None'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.752369</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>910</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=0.5, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.5, 'class_weight': 'None'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.752100</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>910</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=0.7, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.7, 'class_weight': 'None'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.752100</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>910</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=0.9, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.9, 'class_weight': 'None'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.751966</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>910</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=1, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 1, 'class_weight': 'None'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.751917</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>910</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=2, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 2, 'class_weight': 'None'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.752149</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>910</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=5, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 5, 'class_weight': 'None'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.751929</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>910</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=9, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 9, 'class_weight': 'None'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.752039</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>910</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=13, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 13, 'class_weight': 'None'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.751905</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>910</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=15, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 15, 'class_weight': 'None'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.751978</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>910</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=17, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 17, 'class_weight': 'None'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.751880</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>910</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=19, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 19, 'class_weight': 'None'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.752100</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>910</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=21, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 21, 'class_weight': 'None'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.752027</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>910</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=50, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 50, 'class_weight': 'None'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.751941</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>910</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=100, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 100, 'class_weight': 'None'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.752039</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>910</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=1000, class_weight='None', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)</td>\n",
       "      <td>{'penalty': 'l2', 'C': 1000, 'class_weight': 'None'}</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.752063</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>910</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                           model  \\\n",
       "1  LogisticRegression(C=0.001, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)   \n",
       "1  LogisticRegression(C=0.01, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)    \n",
       "1  LogisticRegression(C=0.1, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)     \n",
       "1  LogisticRegression(C=0.3, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)     \n",
       "1  LogisticRegression(C=0.5, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)     \n",
       "1  LogisticRegression(C=0.7, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)     \n",
       "1  LogisticRegression(C=0.9, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)     \n",
       "1  LogisticRegression(C=1, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)       \n",
       "1  LogisticRegression(C=2, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)       \n",
       "1  LogisticRegression(C=5, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)       \n",
       "1  LogisticRegression(C=9, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)       \n",
       "1  LogisticRegression(C=13, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)      \n",
       "1  LogisticRegression(C=15, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)      \n",
       "1  LogisticRegression(C=17, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)      \n",
       "1  LogisticRegression(C=19, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)      \n",
       "1  LogisticRegression(C=21, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)      \n",
       "1  LogisticRegression(C=50, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)      \n",
       "1  LogisticRegression(C=100, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)     \n",
       "1  LogisticRegression(C=1000, class_weight='balanced', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)    \n",
       "1  LogisticRegression(C=0.001, class_weight='None', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)       \n",
       "1  LogisticRegression(C=0.01, class_weight='None', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)        \n",
       "1  LogisticRegression(C=0.1, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)         \n",
       "1  LogisticRegression(C=0.3, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)         \n",
       "1  LogisticRegression(C=0.5, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)         \n",
       "1  LogisticRegression(C=0.7, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)         \n",
       "1  LogisticRegression(C=0.9, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)         \n",
       "1  LogisticRegression(C=1, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)           \n",
       "1  LogisticRegression(C=2, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)           \n",
       "1  LogisticRegression(C=5, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)           \n",
       "1  LogisticRegression(C=9, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)           \n",
       "1  LogisticRegression(C=13, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)          \n",
       "1  LogisticRegression(C=15, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)          \n",
       "1  LogisticRegression(C=17, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)          \n",
       "1  LogisticRegression(C=19, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)          \n",
       "1  LogisticRegression(C=21, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)          \n",
       "1  LogisticRegression(C=50, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)          \n",
       "1  LogisticRegression(C=100, class_weight='None', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\\n          penalty='l2', random_state=None, solver='sag', tol=0.0001,\\n          verbose=0, warm_start=False)         \n",
       "1  LogisticRegression(C=1000, class_weight='None', dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=2, penalty='l2', random_state=None,\\n          solver='sag', tol=0.0001, verbose=0, warm_start=False)        \n",
       "\n",
       "                                                      params algorithm  \\\n",
       "1  {'penalty': 'l2', 'C': 0.001, 'class_weight': 'balanced'}  LR         \n",
       "1  {'penalty': 'l2', 'C': 0.01, 'class_weight': 'balanced'}   LR         \n",
       "1  {'penalty': 'l2', 'C': 0.1, 'class_weight': 'balanced'}    LR         \n",
       "1  {'penalty': 'l2', 'C': 0.3, 'class_weight': 'balanced'}    LR         \n",
       "1  {'penalty': 'l2', 'C': 0.5, 'class_weight': 'balanced'}    LR         \n",
       "1  {'penalty': 'l2', 'C': 0.7, 'class_weight': 'balanced'}    LR         \n",
       "1  {'penalty': 'l2', 'C': 0.9, 'class_weight': 'balanced'}    LR         \n",
       "1  {'penalty': 'l2', 'C': 1, 'class_weight': 'balanced'}      LR         \n",
       "1  {'penalty': 'l2', 'C': 2, 'class_weight': 'balanced'}      LR         \n",
       "1  {'penalty': 'l2', 'C': 5, 'class_weight': 'balanced'}      LR         \n",
       "1  {'penalty': 'l2', 'C': 9, 'class_weight': 'balanced'}      LR         \n",
       "1  {'penalty': 'l2', 'C': 13, 'class_weight': 'balanced'}     LR         \n",
       "1  {'penalty': 'l2', 'C': 15, 'class_weight': 'balanced'}     LR         \n",
       "1  {'penalty': 'l2', 'C': 17, 'class_weight': 'balanced'}     LR         \n",
       "1  {'penalty': 'l2', 'C': 19, 'class_weight': 'balanced'}     LR         \n",
       "1  {'penalty': 'l2', 'C': 21, 'class_weight': 'balanced'}     LR         \n",
       "1  {'penalty': 'l2', 'C': 50, 'class_weight': 'balanced'}     LR         \n",
       "1  {'penalty': 'l2', 'C': 100, 'class_weight': 'balanced'}    LR         \n",
       "1  {'penalty': 'l2', 'C': 1000, 'class_weight': 'balanced'}   LR         \n",
       "1  {'penalty': 'l2', 'C': 0.001, 'class_weight': 'None'}      LR         \n",
       "1  {'penalty': 'l2', 'C': 0.01, 'class_weight': 'None'}       LR         \n",
       "1  {'penalty': 'l2', 'C': 0.1, 'class_weight': 'None'}        LR         \n",
       "1  {'penalty': 'l2', 'C': 0.3, 'class_weight': 'None'}        LR         \n",
       "1  {'penalty': 'l2', 'C': 0.5, 'class_weight': 'None'}        LR         \n",
       "1  {'penalty': 'l2', 'C': 0.7, 'class_weight': 'None'}        LR         \n",
       "1  {'penalty': 'l2', 'C': 0.9, 'class_weight': 'None'}        LR         \n",
       "1  {'penalty': 'l2', 'C': 1, 'class_weight': 'None'}          LR         \n",
       "1  {'penalty': 'l2', 'C': 2, 'class_weight': 'None'}          LR         \n",
       "1  {'penalty': 'l2', 'C': 5, 'class_weight': 'None'}          LR         \n",
       "1  {'penalty': 'l2', 'C': 9, 'class_weight': 'None'}          LR         \n",
       "1  {'penalty': 'l2', 'C': 13, 'class_weight': 'None'}         LR         \n",
       "1  {'penalty': 'l2', 'C': 15, 'class_weight': 'None'}         LR         \n",
       "1  {'penalty': 'l2', 'C': 17, 'class_weight': 'None'}         LR         \n",
       "1  {'penalty': 'l2', 'C': 19, 'class_weight': 'None'}         LR         \n",
       "1  {'penalty': 'l2', 'C': 21, 'class_weight': 'None'}         LR         \n",
       "1  {'penalty': 'l2', 'C': 50, 'class_weight': 'None'}         LR         \n",
       "1  {'penalty': 'l2', 'C': 100, 'class_weight': 'None'}        LR         \n",
       "1  {'penalty': 'l2', 'C': 1000, 'class_weight': 'None'}       LR         \n",
       "\n",
       "        AUC class_0_precision class_0_recall class_0_f1_score class_0_support  \\\n",
       "1  0.755653  0.96              0.71           0.82             910              \n",
       "1  0.752845  0.96              0.69           0.80             910              \n",
       "1  0.748657  0.95              0.70           0.81             910              \n",
       "1  0.747009  0.95              0.70           0.81             910              \n",
       "1  0.746777  0.95              0.70           0.81             910              \n",
       "1  0.746740  0.95              0.70           0.81             910              \n",
       "1  0.746764  0.95              0.70           0.81             910              \n",
       "1  0.746728  0.95              0.70           0.81             910              \n",
       "1  0.746606  0.95              0.70           0.81             910              \n",
       "1  0.746642  0.95              0.70           0.81             910              \n",
       "1  0.746545  0.95              0.70           0.81             910              \n",
       "1  0.746545  0.95              0.70           0.81             910              \n",
       "1  0.746410  0.95              0.70           0.81             910              \n",
       "1  0.746593  0.95              0.70           0.81             910              \n",
       "1  0.746508  0.95              0.70           0.81             910              \n",
       "1  0.746484  0.95              0.70           0.81             910              \n",
       "1  0.746386  0.95              0.70           0.81             910              \n",
       "1  0.746569  0.95              0.70           0.81             910              \n",
       "1  0.746374  0.95              0.70           0.81             910              \n",
       "1  0.742125  0.91              1.00           0.95             910              \n",
       "1  0.755495  0.91              1.00           0.95             910              \n",
       "1  0.753004  0.91              1.00           0.95             910              \n",
       "1  0.752369  0.91              1.00           0.95             910              \n",
       "1  0.752100  0.91              1.00           0.95             910              \n",
       "1  0.752100  0.91              1.00           0.95             910              \n",
       "1  0.751966  0.91              1.00           0.95             910              \n",
       "1  0.751917  0.91              1.00           0.95             910              \n",
       "1  0.752149  0.91              1.00           0.95             910              \n",
       "1  0.751929  0.91              1.00           0.95             910              \n",
       "1  0.752039  0.91              1.00           0.95             910              \n",
       "1  0.751905  0.91              1.00           0.95             910              \n",
       "1  0.751978  0.91              1.00           0.95             910              \n",
       "1  0.751880  0.91              1.00           0.95             910              \n",
       "1  0.752100  0.91              1.00           0.95             910              \n",
       "1  0.752027  0.91              1.00           0.95             910              \n",
       "1  0.751941  0.91              1.00           0.95             910              \n",
       "1  0.752039  0.91              1.00           0.95             910              \n",
       "1  0.752063  0.91              1.00           0.95             910              \n",
       "\n",
       "  class_1_precision class_1_recall class_1_f1_score class_1_support  \\\n",
       "1  0.19              0.68           0.30             90               \n",
       "1  0.18              0.68           0.28             90               \n",
       "1  0.18              0.66           0.28             90               \n",
       "1  0.18              0.64           0.28             90               \n",
       "1  0.18              0.64           0.28             90               \n",
       "1  0.18              0.64           0.28             90               \n",
       "1  0.18              0.64           0.28             90               \n",
       "1  0.18              0.64           0.28             90               \n",
       "1  0.17              0.64           0.27             90               \n",
       "1  0.17              0.64           0.27             90               \n",
       "1  0.17              0.64           0.27             90               \n",
       "1  0.17              0.64           0.27             90               \n",
       "1  0.17              0.64           0.27             90               \n",
       "1  0.17              0.64           0.27             90               \n",
       "1  0.17              0.64           0.27             90               \n",
       "1  0.17              0.64           0.27             90               \n",
       "1  0.17              0.64           0.27             90               \n",
       "1  0.17              0.64           0.27             90               \n",
       "1  0.17              0.64           0.27             90               \n",
       "1  0.00              0.00           0.00             90               \n",
       "1  0.00              0.00           0.00             90               \n",
       "1  0.00              0.00           0.00             90               \n",
       "1  0.00              0.00           0.00             90               \n",
       "1  0.00              0.00           0.00             90               \n",
       "1  0.00              0.00           0.00             90               \n",
       "1  0.00              0.00           0.00             90               \n",
       "1  0.00              0.00           0.00             90               \n",
       "1  0.00              0.00           0.00             90               \n",
       "1  0.00              0.00           0.00             90               \n",
       "1  0.00              0.00           0.00             90               \n",
       "1  0.00              0.00           0.00             90               \n",
       "1  0.00              0.00           0.00             90               \n",
       "1  0.00              0.00           0.00             90               \n",
       "1  0.00              0.00           0.00             90               \n",
       "1  0.00              0.00           0.00             90               \n",
       "1  0.00              0.00           0.00             90               \n",
       "1  0.00              0.00           0.00             90               \n",
       "1  0.00              0.00           0.00             90               \n",
       "\n",
       "  total_precision total_recall total_f1_score total_support  \n",
       "1  0.89            0.71         0.77           1000          \n",
       "1  0.89            0.69         0.76           1000          \n",
       "1  0.88            0.70         0.76           1000          \n",
       "1  0.88            0.69         0.76           1000          \n",
       "1  0.88            0.69         0.76           1000          \n",
       "1  0.88            0.70         0.76           1000          \n",
       "1  0.88            0.69         0.76           1000          \n",
       "1  0.88            0.70         0.76           1000          \n",
       "1  0.88            0.69         0.76           1000          \n",
       "1  0.88            0.69         0.76           1000          \n",
       "1  0.88            0.69         0.76           1000          \n",
       "1  0.88            0.69         0.76           1000          \n",
       "1  0.88            0.69         0.76           1000          \n",
       "1  0.88            0.69         0.76           1000          \n",
       "1  0.88            0.69         0.76           1000          \n",
       "1  0.88            0.69         0.76           1000          \n",
       "1  0.88            0.69         0.76           1000          \n",
       "1  0.88            0.69         0.76           1000          \n",
       "1  0.88            0.69         0.76           1000          \n",
       "1  0.83            0.91         0.87           1000          \n",
       "1  0.83            0.91         0.87           1000          \n",
       "1  0.83            0.91         0.87           1000          \n",
       "1  0.83            0.91         0.87           1000          \n",
       "1  0.83            0.91         0.87           1000          \n",
       "1  0.83            0.91         0.87           1000          \n",
       "1  0.83            0.91         0.87           1000          \n",
       "1  0.83            0.91         0.87           1000          \n",
       "1  0.83            0.91         0.87           1000          \n",
       "1  0.83            0.91         0.87           1000          \n",
       "1  0.83            0.91         0.87           1000          \n",
       "1  0.83            0.91         0.87           1000          \n",
       "1  0.83            0.91         0.87           1000          \n",
       "1  0.83            0.91         0.87           1000          \n",
       "1  0.83            0.91         0.87           1000          \n",
       "1  0.83            0.91         0.87           1000          \n",
       "1  0.83            0.91         0.87           1000          \n",
       "1  0.83            0.91         0.87           1000          \n",
       "1  0.83            0.91         0.87           1000          "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
