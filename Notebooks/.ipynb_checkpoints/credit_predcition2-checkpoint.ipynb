{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_columns=1000\n",
    "pd.options.display.max_rows=1000\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "sys.path.insert(0, \"C:\\\\Users\\\\vberlia\\\\Documents\\\\machine_learning\")\n",
    "import itertools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machineLearning.dataSummary import DataSummary\n",
    "from machineLearning.visualizations import Visualization\n",
    "from machineLearning.ploty_visualization import PlotlyVisualization\n",
    "import plotly.plotly as py\n",
    "from machineLearning.missingValues import MissingValue\n",
    "from machineLearning.models import Model\n",
    "from machineLearning.modelInputs import KNNInputs\n",
    "from machineLearning.pipelines import Pipelines\n",
    "from machineLearning.featureCreation import CreateMeanLookupFeature\n",
    "from machineLearning.featureCreation import CreateMedianLookupFeature\n",
    "from machineLearning.featureCreation import CreateFrequencyLookupFeature\n",
    "from machineLearning.featureCreation import CreateOneHotEncoding\n",
    "from machineLearning.credit_prediction import classification_report\n",
    "from machineLearning.featureCreation import CustomCutter\n",
    "from machineLearning.credit_prediction import raw_features\n",
    "from machineLearning.credit_prediction import create_features\n",
    "from machineLearning.credit_prediction import prep_data\n",
    "from machineLearning.featureCreation import IsMissingFeature\n",
    "from sklearn import linear_model\n",
    "from machineLearning.missingValues import CustomQuantitativeImputer\n",
    "from machineLearning.misc import Misc\n",
    "from machineLearning.missingValues import CustomEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import ggplot\n",
    "from ggplot import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "application_train=pd.read_csv(\"C:/Users/vberlia/Documents/data/credit_prediction/all/application_train.csv\")\n",
    "# application_newData=pd.read_csv(\"C:/Users/vberlia/Documents/data/credit_prediction/all/application_test.csv\")\n",
    "# bureau=pd.read_csv(\"C:/Users/vberlia/Documents/data/credit_prediction/all/bureau.csv\")\n",
    "# bureau_balance=pd.read_csv(\"C:/Users/vberlia/Documents/data/credit_prediction/all/bureau_balance.csv\")\n",
    "# # credit_card_balance=pd.read_csv(\"C:/Users/vberlia/Documents/data/credit_prediction/all/credit_card_balance.csv\")\n",
    "home_credit_col_desc=pd.read_csv(\"C:/Users/vberlia/Documents/data/credit_prediction/all/HomeCredit_columns_description.csv\",encoding = \"ISO-8859-1\")\n",
    "# intall_payment=pd.read_csv(\"C:/Users/vberlia/Documents/data/credit_prediction/all/installments_payments.csv\")\n",
    "# pos_cash=pd.read_csv(\"C:/Users/vberlia/Documents/data/credit_prediction/all/POS_CASH_balance.csv\")\n",
    "# prev_app=pd.read_csv(\"C:/Users/vberlia/Documents/data/credit_prediction/all/previous_application.csv\")\n",
    "# sample_submi=pd.read_csv(\"C:/Users/vberlia/Documents/data/credit_prediction/all/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sample=application_train.sample(10000,random_state=0)\n",
    "train_sample=train_sample.reset_index()\n",
    "original_index=train_sample['index']\n",
    "train_sample=train_sample.drop('index',axis=1)\n",
    "\n",
    "X=train_sample.values\n",
    "Y=train_sample['TARGET']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.10, random_state=42)\n",
    "X_train=pd.DataFrame(X_train)\n",
    "X_train.columns=train_sample.columns\n",
    "X_test=pd.DataFrame(X_test)\n",
    "X_test.columns=train_sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_columns = raw_features.features.raw_columns\n",
    "\n",
    "\"\"\"\n",
    "Enter the create features function\n",
    "and data preparer function\n",
    "\"\"\"\n",
    "final_pipeline=create_features.CreateFeatures.create_all_features1()\n",
    "dataPreparer=prep_data.PrepData.dataPreparer1\n",
    "\n",
    "\"\"\"\n",
    "Fitting Logistic Regression: \n",
    "Setup the hyperparameters\n",
    "\"\"\"\n",
    "\n",
    "algorithm='LR'\n",
    "\n",
    "class_weight=['balanced','None']\n",
    "C=[0.001, 0.01, 0.1, 0.3,0.5,0.7,0.9,1,2,5,9,13,15,17,19,21,50,100,1000]\n",
    "penalty=['l2']\n",
    "\n",
    "# class_weight=['balanced']\n",
    "# C=[21]\n",
    "# penalty=['l2']\n",
    "\n",
    "hyperparams=[class_weight,C,penalty]\n",
    "combs=list(itertools.product(*hyperparams))\n",
    "\n",
    "# Save the result in the file\n",
    "result_file=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model Function\n",
    "def build_model(X_train,standardize_input=1,save_result=False,running_in_cdsw=False):\n",
    "    for col in raw_columns:\n",
    "        X_train[col]=X_train[col].astype('float64')\n",
    "\n",
    "    for col in raw_columns:\n",
    "        X_test[col]=X_test[col].astype('float64')\n",
    "\n",
    "    # Data Preparer function -> should prepare data for all train, test and new data. Because\n",
    "    # every data kind(train, test and new data) goes through the same preparation \n",
    "    # phase\n",
    "    has_fitted_the_main_pipelines=0\n",
    "\n",
    "    X_train['TARGET']=X_train['TARGET'].astype('int')\n",
    "    X_test['TARGET']=X_test['TARGET'].astype('int')\n",
    "    '''\n",
    "    This should be underlying order\n",
    "    '''\n",
    "    X_train_prepared,has_fitted_the_main_pipelines=dataPreparer(X_train,has_fitted_the_main_pipelines,final_pipeline,'train')\n",
    "    X_test_prepared,has_fitted_the_main_pipelines=dataPreparer(X_test,has_fitted_the_main_pipelines,final_pipeline,'test')\n",
    "    if running_in_cdsw:\n",
    "        new_data_prepared,has_fitted_the_main_pipelines=dataPreparer(application_newData,has_fitted_the_main_pipelines,final_pipeline,'new_data')\n",
    "\n",
    "    col_list=X_train_prepared.columns\n",
    "    # Apply scaling\n",
    "    if standardize_input==1:\n",
    "        standardiser= StandardScaler()\n",
    "        X_train_target=X_train_prepared['TARGET']\n",
    "        X_test_target=X_test_prepared['TARGET']\n",
    "\n",
    "        standardiser.fit(X_train_prepared.iloc[:, :-1])\n",
    "        X_train_prepared=pd.DataFrame(standardiser.transform(X_train_prepared.iloc[:, :-1]))\n",
    "        X_train_prepared['TARGET']=X_train_target\n",
    "        X_test_prepared=pd.DataFrame(standardiser.transform(X_test_prepared.iloc[:, :-1]))\n",
    "        X_test_prepared['TARGET']=X_test_target\n",
    "        if running_in_cdsw:\n",
    "            new_data_prepared=pd.DataFrame(standardiser.transform(new_data_prepared))\n",
    "            new_data_prepared.columns=col_list[:-1]\n",
    "\n",
    "    X_train_prepared.columns=col_list\n",
    "    X_test_prepared.columns=col_list\n",
    "#     X_train_prepared.to_csv(\"C:/Users/vberlia/Documents/data/prep1.csv\",index=None)\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    Fitting Logistic Regression: \n",
    "    \"\"\"\n",
    "    all_report=pd.DataFrame()\n",
    "    for param in combs:\n",
    "\n",
    "        model = linear_model.LogisticRegression(solver='sag',n_jobs=2)\n",
    "        params = {\"penalty\":param[2], \"C\":param[1],\"class_weight\":param[0]}\n",
    "\n",
    "        model.set_params(**params)\n",
    "        model.fit(X_train_prepared.iloc[:, :-1], X_train_prepared.iloc[:, -1])\n",
    "        accuracy_lr = model.score(X_test_prepared.iloc[:, :-1], X_test_prepared.iloc[:, -1])        \n",
    "\n",
    "        prediction_result = pd.DataFrame()\n",
    "        predictions = pd.DataFrame(model.predict_proba(X_test_prepared.iloc[:, :-1]))\n",
    "        predictions.columns = ['class_' + str(item) for item in list(model.classes_)]\n",
    "        predictions['true_label'] = X_test_prepared.iloc[:, -1]\n",
    "        predictions['predicted_label'] = model.predict(X_test_prepared.iloc[:, :-1])\n",
    "        predictions['model'] = 'LR'\n",
    "        predictions['pipeline'] = 'no-pipeline'\n",
    "        predictions['param'] = str(params)\n",
    "        prediction_result = pd.concat([prediction_result, predictions])        \n",
    "        report=classification_report.ClassificationReport.showClassificationReport(prediction_result)\n",
    "        report.insert(0, 'algorithm', algorithm)\n",
    "        report.insert(0, 'params', str(params))\n",
    "        report.insert(0, 'model', model)\n",
    "        all_report=pd.concat([all_report,report])\n",
    "    if save_result:    \n",
    "        all_report.to_csv(result_file)\n",
    "    if running_in_cdsw:    \n",
    "        return  new_data_prepared,all_report\n",
    "    else:\n",
    "        return all_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Solver sag supports only l2 penalties, got l1 penalty.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-7cf9694b9f11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mall_report\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-43e87faca097>\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(X_train, standardize_input, save_result, running_in_cdsw)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_prepared\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_prepared\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[0maccuracy_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_prepared\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_prepared\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1221\u001b[0m         _check_solver_option(self.solver, self.multi_class, self.penalty,\n\u001b[1;32m-> 1222\u001b[1;33m                              self.dual)\n\u001b[0m\u001b[0;32m   1223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1224\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'liblinear'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\vberlia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36m_check_solver_option\u001b[1;34m(solver, multi_class, penalty, dual)\u001b[0m\n\u001b[0;32m    441\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpenalty\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'l2'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m             raise ValueError(\"Solver %s supports only l2 penalties, \"\n\u001b[1;32m--> 443\u001b[1;33m                              \"got %s penalty.\" % (solver, penalty))\n\u001b[0m\u001b[0;32m    444\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'liblinear'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdual\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Solver sag supports only l2 penalties, got l1 penalty."
     ]
    }
   ],
   "source": [
    "all_report=build_model(X_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
